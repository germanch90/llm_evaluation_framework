# LLM Configuration
OLLAMA_HOST=http://localhost:11434
LLM_MODEL=llama3.1:8b
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=512

# Embedding Configuration
EMBEDDING_MODEL=nomic-embed-text

# Vector Database
CHROMA_PERSIST_DIRECTORY=./data/vector_db
CHROMA_COLLECTION_NAME=rag_documents

# Chunking Configuration
CHUNK_SIZE=512
CHUNK_OVERLAP=51

# Retrieval Configuration
TOP_K=5

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/rag.log
